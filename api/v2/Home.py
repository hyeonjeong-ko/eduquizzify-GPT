import os
import json
import streamlit as st
from datetime import datetime
from langchain.vectorstores.faiss import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from langchain.prompts import ChatPromptTemplate
from langchain.document_loaders import UnstructuredFileLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain, StuffDocumentsChain, MapReduceDocumentsChain



from prompts import (
    questions_prompt_with_explanation,
    formatting_prompt_with_explanation,
    short_question_prompt,
    short_formatting_prompt,
    learning_cards_prompt,
    learning_cards_formatter_prompt,
)

from pymongo import MongoClient

# youtube
import os
import json
import streamlit as st
import subprocess
from datetime import datetime
import math
from pydub import AudioSegment
import yt_dlp
import glob
import openai


# ì›¹ë¬¸ì„œ ë§í¬
from langchain.document_loaders import AsyncChromiumLoader
from langchain.document_transformers import Html2TextTransformer
import streamlit as st
import re
from langchain.schema import Document


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Card Quiz", page_icon="ğŸ“", layout="centered")


# MongoDB í´ë¼ì´ì–¸íŠ¸ ìƒì„± ë° ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í•¨ìˆ˜
def get_mongo_client():
    client = MongoClient("mongodb://localhost:27017/")  # MongoDB ì„œë²„ì˜ URL
    return client


# MongoDB í´ë¼ì´ì–¸íŠ¸ ìƒì„± ë° ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í•¨ìˆ˜
# MongoDBì— í˜„ì¬ í€´ì¦ˆ ì§ˆë¬¸ë§Œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
# MongoDBì— í€´ì¦ˆ ì¹´ë“œ ì €ì¥ í•¨ìˆ˜
# MongoDBì— í€´ì¦ˆ ì¹´ë“œ ì €ì¥ í•¨ìˆ˜
def save_quiz_to_mongo(card_data, card_type, card_idx):
    try:
        client = get_mongo_client()
        db = client["quiz_db"]

        if card_type == "quiz":
            collection = db["quizzes"]
            question = card_data["questions"][card_idx]

            # ê°ê´€ì‹ í€´ì¦ˆ ì €ì¥
            if "answers" in question:  # ê°ê´€ì‹ í€´ì¦ˆ
                card = {
                    "quiz_type": "multiple",  # ê°ê´€ì‹ í€´ì¦ˆ
                    "question": question["question"],
                    "answers": question.get("answers", None),
                    "explanation": question.get("explanation", None),
                    "timestamp": datetime.now(),
                }
            else:  # ì£¼ê´€ì‹ í€´ì¦ˆ
                card = {
                    "quiz_type": "short",  # ì£¼ê´€ì‹ í€´ì¦ˆ
                    "question": question["question"],
                    "answer": question.get("answer", None),  # ì£¼ê´€ì‹ ë‹µë³€ í•„ë“œ
                    "explanation": question.get("explanation", None),
                    "timestamp": datetime.now(),
                }

        elif card_type == "learning":
            collection = db["learning_cards"]
            card = card_data["learning_cards"][card_idx]
            card["timestamp"] = datetime.now()

        # ì¹´ë“œ ë°ì´í„°ë¥¼ MongoDBì— ì €ì¥
        collection.insert_one(card)
        st.success(f"Card {card_idx + 1}ì´(ê°€) MongoDBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

    except Exception as e:
        st.error(f"MongoDBì— ì¹´ë“œ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    finally:
        client.close()


# ì˜¤ë‹µ ê¸°ë¡ì„ MongoDBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
def save_wrong_answer_to_mongo(question, correct_answer, user_answer, explanation):
    try:
        client = get_mongo_client()
        db = client["quiz_db"]  # 'quiz_db' ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©
        collection = db["wrong_answers"]  # 'wrong_answers' ì»¬ë ‰ì…˜ ì‚¬ìš©

        # ì˜¤ë‹µ ê¸°ë¡ ë°ì´í„°
        wrong_answer_record = {
            "question": question,
            "correct_answer": correct_answer,
            "user_answer": user_answer,
            "explanation": explanation,
            "timestamp": datetime.now(),  # ì˜¤ë‹µ ë°œìƒ ì‹œê°„
        }
        print("##################")
        print(wrong_answer_record)

        # MongoDBì— ì˜¤ë‹µ ê¸°ë¡ ì €ì¥
        collection.insert_one(wrong_answer_record)
        # st.success("ì˜¤ë‹µì´ MongoDBì— ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        st.error(f"MongoDBì— ì˜¤ë‹µ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    finally:
        client.close()


def generate_quiz_from_embeddings(
    embeddings_dir, focus_prompt="", card_type="quiz", question_type="multiple"
):
    try:
        # ì„ë² ë”© ë¡œë“œ
        vectorstore = FAISS.load_local(
            embeddings_dir, OpenAIEmbeddings(), allow_dangerous_deserialization=True
        )
        docs = vectorstore.similarity_search(
            "Retrieve all content from the document.", k=100
        )
        context = "\n\n".join([doc.page_content for doc in docs])
        context += f"\n\nAdditional context: {focus_prompt}"

        # ì¹´ë“œ ìœ í˜•ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ì„¤ì •
        llm = ChatOpenAI(temperature=0.7)

        if card_type == "quiz":  # í€´ì¦ˆ ì¹´ë“œ ìƒì„±
            if question_type == "multiple":
                chain = LLMChain(llm=llm, prompt=questions_prompt_with_explanation)
                formatting_chain = LLMChain(
                    llm=llm, prompt=formatting_prompt_with_explanation
                )
            elif question_type == "short":
                chain = LLMChain(llm=llm, prompt=short_question_prompt)
                formatting_chain = LLMChain(llm=llm, prompt=short_formatting_prompt)
            else:
                raise ValueError("Invalid question type selected")
        elif card_type == "learning":  # í•™ìŠµ ì¹´ë“œ ìƒì„±
            chain = LLMChain(llm=llm, prompt=learning_cards_prompt)
            formatting_chain = LLMChain(llm=llm, prompt=learning_cards_formatter_prompt)
        else:
            raise ValueError(f"Invalid card type selected: {card_type}")

        # ì¹´ë“œ ìƒì„± ë° í¬ë§¤íŒ…
        card_output = chain.run({"context": context})
        formatted_card = formatting_chain.run({"context": card_output})
        card_data = json.loads(formatted_card.replace("```", "").replace("json", ""))

        return card_data

    except Exception as e:
        st.error(f"Error generating cards: {str(e)}")
        return None


# ìƒˆë¡œìš´ í€´ì¦ˆ ìƒì„± ëª¨ë‹¬ í•¨ìˆ˜ ì •ì˜
# ìƒˆë¡œìš´ í€´ì¦ˆ ìƒì„± ëª¨ë‹¬ í•¨ìˆ˜ ì •ì˜
@st.dialog("ë§ˆì§€ë§‰ ì§ˆë¬¸ì…ë‹ˆë‹¤. í€´ì¦ˆë¥¼ ë” ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
def quiz_more_prompt():
    st.write("ì¶”ê°€ í€´ì¦ˆë¥¼ ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")

    # ë²„íŠ¼ ìŠ¤íƒ€ì¼ ì¶”ê°€
    button_style = """
        <style>
        .modal-button {
            width: 80px;  /* ë²„íŠ¼ ë„ˆë¹„ ì¡°ì • */
            background-color: #4CAF50;
            color: white;
            padding: 6px 10px;
            border-radius: 5px;
            border: none;
            font-size: 13px;
            cursor: pointer;
        }
        .modal-button:hover {
            background-color: #45a049;
        }
        </style>
    """
    st.markdown(button_style, unsafe_allow_html=True)

    col1, col2 = st.columns(2)

    with col1:
        if st.button("ì˜ˆ", key="yes_button", help="ì¶”ê°€ í€´ì¦ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤."):
            # í€´ì¦ˆ ì¬ìƒì„± ë¡œì§ ì´ˆê¸°í™”
            st.session_state.current_card = 0  # í˜„ì¬ ì¹´ë“œ ì¸ë±ìŠ¤ ì´ˆê¸°í™”
            st.session_state.quiz_data = None  # ê¸°ì¡´ í€´ì¦ˆ ë°ì´í„° ì´ˆê¸°í™”

            # í˜ì´ì§€ë¥¼ ë‹¤ì‹œ í€´ì¦ˆ ìƒì„±ìœ¼ë¡œ ì„¤ì •
            st.query_params = {"page": "card_generation"}
            st.rerun()  # í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ í€´ì¦ˆ ìƒì„± ë¡œì§ì„ ë‹¤ì‹œ ì‹¤í–‰

    with col2:
        if st.button("ì•„ë‹ˆì˜¤", key="no_button", help="í™ˆ í˜ì´ì§€ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤."):
            # ì•„ë‹ˆì˜¤ë¥¼ ì„ íƒí•˜ë©´ ì„¸ì…˜ì„ ì´ˆê¸°í™”í•˜ê³  í™ˆìœ¼ë¡œ ì´ë™
            st.session_state.clear()  # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            st.query_params = {"page": "quiz"}  # ì²« í˜ì´ì§€ë¡œ ì´ë™ ì„¤ì •
            st.rerun()


# í€´ì¦ˆ ìƒì„± í•¨ìˆ˜ ì •ì˜
# ì„ë² ë”©ê³¼ ì¹´ë“œë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (í€´ì¦ˆ ì¹´ë“œì™€ í•™ìŠµ ì¹´ë“œë¥¼ ì²˜ë¦¬)
def generate_cards_from_embeddings(
    embeddings_dir, focus_prompt="", card_type="quiz", question_type="multiple"
):
    try:
        # ì„ë² ë”© ë¡œë“œ
        vectorstore = FAISS.load_local(embeddings_dir, OpenAIEmbeddings())
        docs = vectorstore.similarity_search(
            "Retrieve all content from the document.", k=100
        )
        context = "\n\n".join([doc.page_content for doc in docs])
        context += f"\n\nAdditional context: {focus_prompt}"

        # ì¹´ë“œ ìœ í˜•ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ì„¤ì •
        llm = ChatOpenAI(temperature=0.7)

        if card_type == "quiz":  # í€´ì¦ˆ ì¹´ë“œ ìƒì„±
            if question_type == "multiple":
                chain = LLMChain(llm=llm, prompt=questions_prompt_with_explanation)
                formatting_chain = LLMChain(
                    llm=llm, prompt=formatting_prompt_with_explanation
                )
            elif question_type == "short":
                chain = LLMChain(llm=llm, prompt=short_question_prompt)
                formatting_chain = LLMChain(llm=llm, prompt=short_formatting_prompt)
            else:
                raise ValueError("Invalid question type selected")
        elif card_type == "learning":  # í•™ìŠµ ì¹´ë“œ ìƒì„±
            chain = LLMChain(llm=llm, prompt=learning_cards_prompt)
            formatting_chain = LLMChain(llm=llm, prompt=learning_cards_formatter_prompt)
        else:
            raise ValueError(f"Invalid card type selected: {card_type}")

        # ì¹´ë“œ ìƒì„± ë° í¬ë§¤íŒ…
        card_output = chain.run({"context": context})
        formatted_card = formatting_chain.run({"context": card_output})
        card_data = json.loads(formatted_card.replace("```", "").replace("json", ""))

        return card_data

    except Exception as e:
        st.error(f"Error generating cards: {str(e)}")
        return None


# íŒŒì¼ ì €ì¥ ê²½ë¡œ ìƒì„± í•¨ìˆ˜
def save_uploaded_file(uploaded_file):
    current_date = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_dir = (
        f"./.cache/file_embeddings/{current_date}_{uploaded_file.name.split('.')[0]}"
    )
    os.makedirs(save_dir, exist_ok=True)
    file_path = os.path.join(save_dir, uploaded_file.name)

    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    return file_path, save_dir


# ì„ë² ë”© ìƒì„± ë° ì €ì¥ í•¨ìˆ˜
def create_embedding(file_path, save_dir):
    loader = UnstructuredFileLoader(file_path)
    splitter = CharacterTextSplitter(chunk_size=600, chunk_overlap=100)
    docs = loader.load_and_split(text_splitter=splitter)

    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(docs, embeddings)
    vectorstore.save_local(save_dir)

    return f"{save_dir}/index.faiss", f"{save_dir}/index.pkl"


# í˜„ì¬ í€´ì¦ˆì˜ ì¸ë±ìŠ¤ë¥¼ ê´€ë¦¬
def show_quiz_card(quiz_data, question_idx):
    question = quiz_data["questions"][question_idx]
    st.subheader(f"Question {question_idx + 1}: {question['question']}")
    user_answer = st.radio(
        "Select your answer:", [a["answer"] for a in question["answers"]]
    )

    if st.button("Submit Answer"):
        correct_answer = next(a["answer"] for a in question["answers"] if a["correct"])
        if user_answer == correct_answer:
            st.success(f"ì •ë‹µì…ë‹ˆë‹¤! {correct_answer}")
        else:
            st.error(f"ì˜¤ë‹µì…ë‹ˆë‹¤. ì •ë‹µì€ {correct_answer}ì…ë‹ˆë‹¤.")

            st.write("save_wrong_answerì‹¤í–‰!!!!!!!!!!!")
            # ì‚¬ìš©ìê°€ í‹€ë¦° ë¬¸ì œë¥¼ MongoDBì— ì €ì¥
            save_wrong_answer_to_mongo(
                question["question"],
                correct_answer,
                user_answer,
                question["explanation"],
            )

        st.write(f"**Explanation**: {question['explanation']}")


def show_short_answer_card(quiz_data, question_idx):
    question = quiz_data["questions"][question_idx]
    st.subheader(f"Question {question_idx + 1}: {question['question']}")
    user_answer_key = f"user_answer_{question_idx}"
    user_answer = st.text_input("Enter your answer:", key=user_answer_key)

    if st.button("Submit Answer"):
        st.success(f"Correct Answer: {question['answer']}")


# í˜ì´ì§€ ìƒíƒœ ê´€ë¦¬
# í•™ìŠµ ì¹´ë“œ ë˜ëŠ” í€´ì¦ˆ ì¹´ë“œë¥¼ í™”ë©´ì— í‘œì‹œí•˜ëŠ” í•¨ìˆ˜
# ì¹´ë“œ ë³´ì—¬ì£¼ê¸° í•¨ìˆ˜
def show_card(card_data, card_type, card_idx):
    if card_type == "quiz":
        question = card_data["questions"][card_idx]
        st.subheader(f"Card {card_idx + 1}")
        st.write(f"**Question**: {question['question']}")

        if "answers" in question:
            user_answer = st.radio(
                "Select your answer:", [a["answer"] for a in question["answers"]]
            )
            if st.button("Submit Answer"):
                correct_answer = next(
                    a["answer"] for a in question["answers"] if a["correct"]
                )
                if user_answer == correct_answer:
                    st.success(f"ì •ë‹µì…ë‹ˆë‹¤! {correct_answer}")
                else:
                    st.error(f"ì˜¤ë‹µì…ë‹ˆë‹¤. ì •ë‹µì€ {correct_answer}ì…ë‹ˆë‹¤.")
                    # ì‚¬ìš©ìê°€ í‹€ë¦° ë¬¸ì œë¥¼ MongoDBì— ì €ì¥
                    save_wrong_answer_to_mongo(
                        question["question"],
                        correct_answer,
                        user_answer,
                        question["explanation"],
                    )

                st.write(
                    f"**Explanation**: {question.get('explanation', 'No explanation available.')}"
                )
        else:
            user_answer = st.text_input("Enter your answer:")
            if st.button("Submit Answer"):
                st.success(f"Correct Answer: {question['answer']}")

    elif card_type == "learning":
        card = card_data["learning_cards"][card_idx]
        st.subheader(f"Card {card_idx + 1}")
        st.write(f"**Statement**: {card['statement']}")
        st.write(f"**Question**: {card['question']}")
        if "explanation" in card:
            st.write(f"**Explanation**: {card['explanation']}")


def preprocess_blog_content(raw_content):
    """
    ì£¼ì–´ì§„ ë¸”ë¡œê·¸ í…ìŠ¤íŠ¸ì—ì„œ ë¶ˆí•„ìš”í•œ ì •ë³´(ë©”ë‰´, ì¹´í…Œê³ ë¦¬, ëŒ“ê¸€, í†µê³„ ë“±)ë¥¼ ì œê±°í•˜ê³ 
    ë³¸ë¬¸ë§Œ ë‚¨ê¸°ëŠ” ì „ì²˜ë¦¬ í•¨ìˆ˜.

    Parameters:
    raw_content (list of Document or str): ë¸”ë¡œê·¸ì˜ ì›ì‹œ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë‚˜ ë‹¨ì¼ í…ìŠ¤íŠ¸

    Returns:
    str: ì „ì²˜ë¦¬ëœ ë³¸ë¬¸ í…ìŠ¤íŠ¸
    """
    # ë§Œì•½ raw_contentê°€ Document ê°ì²´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸ë¼ë©´ ê° page_contentë¥¼ ì¶”ì¶œí•˜ì—¬ ê²°í•©
    if isinstance(raw_content, list):
        raw_content = "\n".join(
            [doc.page_content for doc in raw_content if isinstance(doc, Document)]
        )

    # 1. HTML íƒœê·¸ ì œê±°
    cleaned_content = re.sub(r"<.*?>", "", raw_content)

    # 2. ë¶ˆí•„ìš”í•œ ë©”ë‰´/ì¹´í…Œê³ ë¦¬/íƒœê·¸ ê´€ë ¨ ì •ë³´ ì œê±°
    patterns_to_remove = [
        r"ë°”ë¡œê°€ê¸°.*?ë‹«ê¸°",  # ë©”ë‰´ ê´€ë ¨ í…ìŠ¤íŠ¸ ì œê±°
        r"CATEGORY.*?(\n\n|\\n\\n)",  # ì¹´í…Œê³ ë¦¬ ë° í•˜ìœ„ ë©”ë‰´ ì œê±°
        r"TAG.*?(\n\n|\\n\\n)",  # íƒœê·¸ ì œê±°
        r"ê³µìœ í•˜ê¸°.*?\n\n",  # ê³µìœ í•˜ê¸° ê´€ë ¨ ì •ë³´ ì œê±°
        r"ìµœê·¼ì— ì˜¬ë¼ì˜¨ ê¸€.*?\n\n",  # ìµœê·¼ ê¸€ ë¦¬ìŠ¤íŠ¸ ì œê±°
        r"ìµœê·¼ì— ë‹¬ë¦° ëŒ“ê¸€.*?\n\n",  # ìµœê·¼ ëŒ“ê¸€ ë¦¬ìŠ¤íŠ¸ ì œê±°
        r"ëŒ“ê¸€ì“°ê¸° í¼.*?\n\n",  # ëŒ“ê¸€ í¼ ì œê±°
        r"Powered by.*?Tistory",  # Tistory ê´€ë ¨ í‘¸í„° ì •ë³´ ì œê±°
        r"\n{2,}",  # ì—°ì†ì ì¸ ë¹ˆ ì¤„ ì œê±°
        r"\s*ë°˜ì‘í˜•\s*",  # 'ë°˜ì‘í˜•' í…ìŠ¤íŠ¸ ì œê±°
        r"^\s*$",  # ë¹ˆ ì¤„ ì œê±°
        r"ë‹¨ì¶•í‚¤.*?\n\n",  # ë‹¨ì¶•í‚¤ ì•ˆë‚´ ì œê±°
    ]

    for pattern in patterns_to_remove:
        cleaned_content = re.sub(pattern, "", cleaned_content, flags=re.DOTALL)

    # 3. ê¸°íƒ€ ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
    cleaned_content = re.sub(r"\s+", " ", cleaned_content).strip()

    return cleaned_content


# MapReduce ìš”ì•½ ìƒì„± í•¨ìˆ˜
# MapReduce ìš”ì•½ ìƒì„± í•¨ìˆ˜
def summarize_youtube_script_with_map_reduce(transcript_path, user_request):
    # ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
    loader = UnstructuredFileLoader(transcript_path)
    splitter = CharacterTextSplitter(chunk_size=600, chunk_overlap=100)
    docs = loader.load_and_split(text_splitter=splitter)

    # ìš”ì•½ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì •ì˜ (Map ë‹¨ê³„)
    map_prompt_template = """
    Summarize the following transcript chunk, focusing on the user's request: {user_request}
    Text: {input_documents}
    """
    map_prompt = PromptTemplate.from_template(map_prompt_template)

    # Map ë‹¨ê³„ì˜ LLMChain ì •ì˜
    map_chain = LLMChain(
        llm=ChatOpenAI(temperature=0.7), prompt=map_prompt
    )

    # ìš”ì•½ì„ ê²°í•©í•˜ê¸° ìœ„í•œ Reduce ë‹¨ê³„ì˜ í”„ë¡¬í”„íŠ¸ ì •ì˜
    reduce_prompt_template = """
    Combine the following summaries into a concise summary, focusing on the user's request: {user_request}
    Summaries: {input_documents}
    """
    reduce_prompt = PromptTemplate.from_template(reduce_prompt_template)

    # Reduce ë‹¨ê³„ì˜ LLMChain ì •ì˜
    reduce_llm_chain = LLMChain(
        llm=ChatOpenAI(temperature=0.7), prompt=reduce_prompt
    )

    # Reduce ë‹¨ê³„ë¥¼ ìœ„í•´ StuffDocumentsChain ì‚¬ìš©
    reduce_documents_chain = StuffDocumentsChain(
        llm_chain=reduce_llm_chain, document_variable_name="input_documents"
    )

    # MapReduce ë¬¸ì„œ ì²´ì¸ êµ¬ì„±
    map_reduce_chain = MapReduceDocumentsChain(
        llm_chain=map_chain,  # Map ë‹¨ê³„
        reduce_documents_chain=reduce_documents_chain,  # Reduce ë‹¨ê³„
        document_variable_name="input_documents"  # ì²­í¬ ì²˜ë¦¬
    )

    # ìµœì¢… ìš”ì•½ì„ ìƒì„±
    final_summary = map_reduce_chain.run({
        "input_documents": docs,  # ë¬¸ì„œ ì²­í¬
        "user_request": user_request  # ì‚¬ìš©ì ìš”ì²­ ë°˜ì˜
    })

    return final_summary


# í˜ì´ì§€ ìƒíƒœ ê´€ë¦¬
query_params = st.query_params

# í˜ì´ì§€ ê´€ë¦¬
if "page" in query_params:
    page = query_params["page"]
else:
    page = "quiz"

# íŒŒì¼ ì—…ë¡œë“œ ìƒíƒœ ê´€ë¦¬
if "uploaded_file" not in st.session_state:
    st.session_state["uploaded_file"] = None

# ì¹´ë“œ ë°ì´í„° ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "card_data" not in st.session_state:
    st.session_state.card_data = None

if "current_card" not in st.session_state:
    st.session_state.current_card = 0

# í˜ì´ì§€ì— ë”°ë¥¸ í™”ë©´ í‘œì‹œ
if page == "quiz":
    st.title("ìë£Œ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”")
    options = [
        "ê³µì‹ docs ë§í¬",
        "ì›¹ë¬¸ì„œ ìë£Œ ë§í¬",
        "ê°œì¸ íŒŒì¼ ì—…ë¡œë“œ (PDF, TXT)",
        "ìœ íŠœë¸Œ ì˜ìƒ ë§í¬",
    ]

    selection = st.radio("", options)
    if st.button("Next"):
        if selection == "ê°œì¸ íŒŒì¼ ì—…ë¡œë“œ (PDF, TXT)":
            st.query_params = {"page": "file_upload"}  # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì„¤ì •
        elif selection == "ìœ íŠœë¸Œ ì˜ìƒ ë§í¬":
            st.query_params = {
                "page": "youtube_input"
            }  # ìœ íŠœë¸Œ ë§í¬ ì…ë ¥ í˜ì´ì§€ë¡œ ì´ë™
        elif selection == "ì›¹ë¬¸ì„œ ìë£Œ ë§í¬":
            st.query_params = {"page": "web_input"}

# ìœ íŠœë¸Œ ì˜ìƒ ë§í¬ì¼ë•Œ#####################


# ìœ íŠœë¸Œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ë° mp3ë¡œ ì¶”ì¶œ í•¨ìˆ˜
def download_audio_with_ytdlp(youtube_link, output_path):
    ydl_opts = {
        "format": "bestaudio/best",
        "postprocessors": [
            {
                "key": "FFmpegExtractAudio",
                "preferredcodec": "mp3",
                "preferredquality": "192",
            }
        ],
        "outtmpl": f"{output_path}/%(title)s.%(ext)s",  # ì˜ìƒëª…ì— ë”°ë¼ ì €ì¥
    }

    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(
            youtube_link, download=True
        )  # ì˜ìƒ ì •ë³´ì™€ í•¨ê»˜ ë‹¤ìš´ë¡œë“œ
        return info["title"]  # ë‹¤ìš´ë¡œë“œëœ ì˜ìƒì˜ ì œëª© ë°˜í™˜


# mp3ë¥¼ 10ë¶„ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ì²­í¬ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
def split_audio_into_chunks(audio_path, chunk_dir, chunk_duration=10):
    track = AudioSegment.from_mp3(audio_path)
    ten_minutes = chunk_duration * 60 * 1000  # 10ë¶„ ë‹¨ìœ„
    chunks = math.ceil(len(track) / ten_minutes)

    os.makedirs(chunk_dir, exist_ok=True)  # ì²­í¬ ë””ë ‰í† ë¦¬ ìƒì„±

    for i in range(chunks):
        start_time = i * ten_minutes
        end_time = (i + 1) * ten_minutes

        chunk = track[start_time:end_time]
        chunk.export(f"{chunk_dir}/chunk_{i}.mp3", format="mp3")


# OpenAI Whisper APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ì²­í¬ íŒŒì¼ì˜ ìë§‰ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
def transcribe_chunks(chunk_folder, destination):
    # ì²­í¬ íŒŒì¼ë“¤ì„ globì„ í†µí•´ ê°€ì ¸ì˜´
    files = glob.glob(f"{chunk_folder}/*.mp3")

    # íŒŒì¼ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
    for file in files:
        with open(file, "rb") as audio_file, open(destination, "a") as text_file:
            # OpenAI APIë¥¼ ì‚¬ìš©í•´ ìë§‰ ìƒì„±
            transcript = openai.Audio.transcribe(
                "whisper-1",
                audio_file,
            )
            # ìë§‰ì„ íŒŒì¼ì— ì €ì¥
            text_file.write(transcript["text"] + "\n")


# Refine ìš”ì•½ ìƒì„±
def refine_summary(transcript_path, user_request):
    loader = UnstructuredFileLoader(transcript_path)
    splitter = CharacterTextSplitter(chunk_size=600, chunk_overlap=100)
    docs = loader.load_and_split(text_splitter=splitter)

    llm = ChatOpenAI(temperature=0.1)
    first_summary_prompt = ChatPromptTemplate.from_template(
        """
        Write a concise summary of the following, considering the user's request: "{user_request}"
        "{text}"
        CONCISE SUMMARY:                
    """
    )
    first_summary_chain = LLMChain(llm=llm, prompt=first_summary_prompt)
    summary = first_summary_chain.run(
        {"text": docs[0].page_content, "user_request": user_request}
    )

    refine_prompt = ChatPromptTemplate.from_template(
        """
        Refine the existing summary using the following context:
        "{context}"
        Considering the user's request: "{user_request}"
        REFINED SUMMARY:                
    """
    )
    refine_chain = LLMChain(llm=llm, prompt=refine_prompt)

    for doc in docs[1:]:
        summary = refine_chain.run(
            {
                "existing_summary": summary,
                "context": doc.page_content,
                "user_request": user_request,
            }
        )

    return summary


# ìœ íŠœë¸Œ ì˜ìƒ ì²˜ë¦¬ í˜ì´ì§€

# ì›¹ ìë£Œ ì…ë ¥ í˜ì´ì§€
if page == "web_input":
    st.title("ì›¹ URLì„ ì…ë ¥í•˜ì„¸ìš”")
    web_url = st.text_input("ì›¹ ìë£Œ ë§í¬", placeholder="https://example.com")

    if st.button("Submit"):
        if web_url:
            st.session_state["web_url"] = web_url
            st.success("ì›¹ ë§í¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.query_params = {"page": "web_processing"}
            st.rerun()
        else:
            st.error("ì›¹ ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

# ì›¹ ìë£Œ ì²˜ë¦¬ í˜ì´ì§€
# ì›¹ ìë£Œ ì²˜ë¦¬ í˜ì´ì§€
if page == "web_processing":
    st.title("ì›¹ ì½˜í…ì¸ ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    web_url = st.session_state["web_url"]

    with st.spinner("ì›¹ í˜ì´ì§€ì—ì„œ ì½˜í…ì¸ ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        loader = AsyncChromiumLoader([web_url])
        docs = loader.load()
        html2text_transformer = Html2TextTransformer()
        transformed_docs = html2text_transformer.transform_documents(docs)

    # ì›¹ ì½˜í…ì¸  ì „ì²˜ë¦¬
    cleaned_content = preprocess_blog_content(transformed_docs)
    # st.write(cleaned_content)

    st.session_state["web_content"] = (
        cleaned_content  # ì „ì²˜ë¦¬ëœ ì›¹ ì½˜í…ì¸ ë¥¼ ì„¸ì…˜ì— ì €ì¥
    )
    st.success("ì›¹ ì½˜í…ì¸ ê°€ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")

    # ì¶”ê°€ ìš”ì²­ ì‚¬í•­ ì…ë ¥ ë° ì¹´ë“œ ì„ íƒ
    st.title("í€´ì¦ˆ ë˜ëŠ” í•™ìŠµ ì¹´ë“œ ì„¤ì •")

    additional_request = st.text_area(
        "ì¶”ê°€ ìš”ì²­ ì‚¬í•­ ì…ë ¥", placeholder="ì˜ˆ: íŠ¹ì • ì£¼ì œì— ì§‘ì¤‘"
    )

    # ì¹´ë“œ ìœ í˜• ì„ íƒ (í€´ì¦ˆ ì¹´ë“œ or í•™ìŠµ ì¹´ë“œ)
    card_type_selection = st.radio("ì¹´ë“œ ìœ í˜• ì„ íƒ:", ("í€´ì¦ˆ ì¹´ë“œ", "í•™ìŠµ ì¹´ë“œ"))
    card_type = "quiz" if card_type_selection == "í€´ì¦ˆ ì¹´ë“œ" else "learning"

    # ì§ˆë¬¸ ìœ í˜• ì„ íƒ (í€´ì¦ˆ ì¹´ë“œì¼ ê²½ìš°ë§Œ)
    if card_type == "quiz":
        question_type_selection = st.radio("ì§ˆë¬¸ ìœ í˜• ì„ íƒ:", ("ê°ê´€ì‹", "ì£¼ê´€ì‹"))
        question_type = "multiple" if question_type_selection == "ê°ê´€ì‹" else "short"
    else:
        question_type = None  # í•™ìŠµ ì¹´ë“œì¼ ê²½ìš° ì§ˆë¬¸ ìœ í˜•ì€ í•„ìš” ì—†ìŒ

    # ì¹´ë“œ ìƒì„± ë²„íŠ¼
    if st.button("ì¹´ë“œ ìƒì„±"):
        st.session_state["additional_request"] = additional_request
        st.session_state["card_type"] = card_type
        st.session_state["question_type"] = question_type
        st.query_params = {"page": "web_card_generation"}  # ì¹´ë“œ ìƒì„± í˜ì´ì§€ë¡œ ì´ë™
        st.rerun()

# ì›¹ ê¸°ë°˜ ì¹´ë“œ ìƒì„± í˜ì´ì§€
if page == "web_card_generation":
    st.title("ì¹´ë“œ ìƒì„± ì¤‘...")

    # ì„¸ì…˜ì—ì„œ ì›¹ ì½˜í…ì¸ ì™€ ì¶”ê°€ ìš”ì²­ ì‚¬í•­ ë¶ˆëŸ¬ì˜¤ê¸°
    web_content = st.session_state.get("web_content", "")
    additional_request = st.session_state.get("additional_request", "")

    # ì¹´ë“œ ìœ í˜•ê³¼ ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ì„ë² ë”© ìƒì„± ë° ì¹´ë“œ ìƒì„±
    with st.spinner("ì¹´ë“œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            # ì„ë² ë”© ìƒì„±ì— í•„ìš”í•œ ì •ë³´
            embeddings_dir = (
                f"./.cache/web_embeddings/{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            )
            os.makedirs(embeddings_dir, exist_ok=True)

            # ì›¹ ì½˜í…ì¸ ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„ë² ë”© ìƒì„±
            summary_file_path = f"{embeddings_dir}/web_content.txt"
            with open(summary_file_path, "w") as f:
                f.write(web_content)

            faiss_path, pkl_path = create_embedding(summary_file_path, embeddings_dir)

            # ì„¸ì…˜ì— ì„ë² ë”© ê²½ë¡œ ì €ì¥
            st.session_state["faiss_path"] = faiss_path
            st.session_state["pkl_path"] = pkl_path

            # ì¹´ë“œ ìƒì„± í˜¸ì¶œ
            card_data = generate_quiz_from_embeddings(
                embeddings_dir,
                additional_request,
                st.session_state["card_type"],
                st.session_state["question_type"],
            )

            if card_data:
                st.success("ì¹´ë“œ ìƒì„± ì™„ë£Œ!")
                st.session_state.card_data = (
                    card_data  # ìƒì„±ëœ ì¹´ë“œ ë°ì´í„°ë¥¼ ì„¸ì…˜ì— ì €ì¥
                )
                st.query_params = {"page": "card_display"}  # ì¹´ë“œ í‘œì‹œ í˜ì´ì§€ë¡œ ì´ë™
                st.rerun()
            else:
                st.error("ì¹´ë“œ ìƒì„± ì‹¤íŒ¨!")
        except Exception as e:
            st.error(f"ì„ë² ë”© ìƒì„± ë° ì¹´ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# ìœ íŠœë¸Œ ì˜ìƒ ì²˜ë¦¬ í˜ì´ì§€
if page == "youtube_input":
    st.title("ìœ íŠœë¸Œ ì˜ìƒ ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
    youtube_link = st.text_input(
        "ìœ íŠœë¸Œ ì˜ìƒ ë§í¬", placeholder="ìœ íŠœë¸Œ URLì„ ì…ë ¥í•˜ì„¸ìš”"
    )

    if st.button("Submit"):
        if youtube_link:
            st.session_state["youtube_link"] = youtube_link
            st.success("ìœ íŠœë¸Œ ë§í¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.query_params = {"page": "quiz_settings"}
            st.rerun()
        else:
            st.error("ìœ íŠœë¸Œ ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")


# í€´ì¦ˆ ì„¤ì • í˜ì´ì§€
if page == "quiz_settings":
    st.title("í€´ì¦ˆ ì„¤ì •")

    additional_request = st.text_area(
        "í€´ì¦ˆ ìƒì„±ì— ëŒ€í•œ ì¶”ê°€ ìš”ì²­ ì‚¬í•­ ì…ë ¥", placeholder="ì˜ˆ: íŠ¹ì • ì£¼ì œì— ì§‘ì¤‘"
    )

    card_type_selection = st.radio("ì¹´ë“œ ìœ í˜• ì„ íƒ:", ("í€´ì¦ˆ ì¹´ë“œ", "í•™ìŠµ ì¹´ë“œ"))
    card_type = "quiz" if card_type_selection == "í€´ì¦ˆ ì¹´ë“œ" else "learning"

    if card_type == "quiz":
        question_type_selection = st.radio("ì§ˆë¬¸ ìœ í˜• ì„ íƒ:", ("ê°ê´€ì‹", "ì£¼ê´€ì‹"))
        question_type = "multiple" if question_type_selection == "ê°ê´€ì‹" else "short"
    else:
        question_type = None

    if st.button("ì¹´ë“œ ìƒì„±"):
        st.session_state["additional_request"] = additional_request
        st.session_state["card_type"] = card_type
        st.session_state["question_type"] = question_type
        st.query_params = {"page": "youtube_processing"}
        st.rerun()


# ìœ íŠœë¸Œ ì˜ìƒ ì²˜ë¦¬ ë° ì¹´ë“œ ìƒì„±
if page == "youtube_processing":
    st.title("ìœ íŠœë¸Œ ì˜ìƒ ì²˜ë¦¬ ì¤‘...")

    youtube_link = st.session_state["youtube_link"]
    additional_request = st.session_state["additional_request"]

    current_date = datetime.now().strftime("%Y%m%d_%H%M%S")
    video_dir = f"./files/youtube/{current_date}"
    os.makedirs(video_dir, exist_ok=True)

    with st.spinner("ìœ íŠœë¸Œì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ë‹¤ìš´ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤..."):
        video_title = download_audio_with_ytdlp(youtube_link, video_dir)
        audio_path = f"{video_dir}/{video_title}.mp3"

    with st.spinner("ì˜¤ë””ì˜¤ë¥¼ 10ë¶„ ë‹¨ìœ„ë¡œ ì²­í¬ ë¶„í•  ì¤‘ì…ë‹ˆë‹¤..."):
        chunk_dir = f"{video_dir}/chunks"
        split_audio_into_chunks(audio_path, chunk_dir)

    transcription_file = f"{video_dir}/transcription.txt"
    with st.spinner("OpenAI Whisperë¡œ ìë§‰ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        transcribe_chunks(chunk_dir, transcription_file)

    # with st.spinner("ìš”ì•½ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
    #     summary = refine_summary(transcription_file, additional_request)
    #     st.session_state["summary"] = summary

    with st.spinner("MapReduceë¡œ ìš”ì•½ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        summary = summarize_youtube_script_with_map_reduce(
            transcription_file, additional_request
        )
        st.session_state["summary"] = summary

    embeddings_dir = f"./.cache/youtube_embeddings/{current_date}"
    os.makedirs(embeddings_dir, exist_ok=True)

    with st.spinner("ìš”ì•½ëœ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì„ë² ë”©ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            summary_file_path = f"{video_dir}/summary.txt"
            with open(summary_file_path, "w") as f:
                f.write(summary)

            faiss_path, pkl_path = create_embedding(summary_file_path, embeddings_dir)

            st.session_state["faiss_path"] = faiss_path
            st.session_state["pkl_path"] = pkl_path
            st.session_state["embeddings_dir"] = embeddings_dir

        except Exception as e:
            st.error(f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.stop()

    st.success(f"ìš”ì•½ ë° ì„ë² ë”© ìƒì„± ì™„ë£Œ! ì´ì œ ì¹´ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    st.query_params = {"page": "card_generation"}
    st.rerun()

###################################################################


elif page == "file_upload":
    st.title("ìë£Œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”")

    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("PDF ë˜ëŠ” TXT íŒŒì¼ ì—…ë¡œë“œ", type=["pdf", "txt"])
    if uploaded_file is not None:
        st.session_state["uploaded_file_path"], save_dir = save_uploaded_file(
            uploaded_file
        )
        st.write(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")

        additional_request = st.text_area(
            "ì‘ì—… ì¶”ê°€ ìš”ì²­ ë‚´ìš© ì…ë ¥ (ì„ íƒ ì‚¬í•­)",
            placeholder="ì˜ˆ: íŠ¹ì • í•µì‹¬ ë‚´ìš©ë§Œ, í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš” ë“±",
        )

        card_type_selection = st.radio("ì¹´ë“œ ìœ í˜• ì„ íƒ:", ("í€´ì¦ˆ ì¹´ë“œ", "í•™ìŠµ ì¹´ë“œ"))
        card_type = "quiz" if card_type_selection == "í€´ì¦ˆ ì¹´ë“œ" else "learning"

        # ì§ˆë¬¸ ìœ í˜• (í€´ì¦ˆ ì¹´ë“œì¼ ê²½ìš°ë§Œ ì„ íƒ)
        if card_type == "quiz":
            question_type_selection = st.radio("ì§ˆë¬¸ ìœ í˜• ì„ íƒ:", ("ê°ê´€ì‹", "ì£¼ê´€ì‹"))

            # Map the selection to internal types
            if question_type_selection == "ê°ê´€ì‹":
                question_type = "multiple"
            elif question_type_selection == "ì£¼ê´€ì‹":
                question_type = "short"
        else:
            question_type = None  # í•™ìŠµ ì¹´ë“œì¼ ê²½ìš° ì§ˆë¬¸ ìœ í˜• í•„ìš” ì—†ìŒ

        if st.button("ì„ë² ë”© ìƒì„± ë° ë‹¤ìŒ ë‹¨ê³„"):
            st.session_state["additional_request"] = additional_request
            st.session_state["card_type"] = card_type
            st.session_state["question_type"] = question_type

            # ì„ë² ë”© ìƒì„± ì‹œ ë¡œë”© ìŠ¤í”¼ë„ˆ ì¶”ê°€
            with st.spinner("ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."):
                faiss_path, pkl_path = create_embedding(
                    st.session_state["uploaded_file_path"], save_dir
                )

            # ì„ë² ë”© íŒŒì¼ ê²½ë¡œ ì„¸ì…˜ ì €ì¥
            st.session_state["faiss_path"] = faiss_path
            st.session_state["pkl_path"] = pkl_path
            st.session_state["embeddings_dir"] = save_dir  # ì„ë² ë”© ë””ë ‰í„°ë¦¬ ì €ì¥

            # ì¹´ë“œ ìƒì„± í˜ì´ì§€ë¡œ ì´ë™
            st.query_params = {"page": "card_generation"}  # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì„¤ì •
            st.rerun()  # í˜ì´ì§€ ë¦¬ë¡œë“œ

elif page == "card_generation":
    st.title("ì¹´ë“œ ìƒì„± ì¤‘...")

    # "uploaded_file_path"ê°€ ì„¸ì…˜ ìƒíƒœì— ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ê¸°ë³¸ê°’ ì„¤ì •
    if "uploaded_file_path" in st.session_state:
        st.write(f"ì—…ë¡œë“œëœ íŒŒì¼: {st.session_state['uploaded_file_path']}")
    else:
        st.warning("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    if "faiss_path" in st.session_state:
        st.write(f"FAISS ê²½ë¡œ: {st.session_state['faiss_path']}")
    else:
        st.warning("FAISS ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    if "pkl_path" in st.session_state:
        st.write(f"PKL ê²½ë¡œ: {st.session_state['pkl_path']}")
    else:
        st.warning("PKL ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    st.write(
        f"ì„ íƒí•œ ì¹´ë“œ ìœ í˜•: {st.session_state.get('card_type', 'ì¹´ë“œ ìœ í˜•ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')}"
    )
    if st.session_state.get("card_type") == "quiz":
        st.write(
            f"ì„ íƒí•œ ì§ˆë¬¸ ìœ í˜•: {st.session_state.get('question_type', 'ì§ˆë¬¸ ìœ í˜•ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')}"
        )
    st.write(
        f"ì¶”ê°€ ìš”ì²­ ì‚¬í•­: {st.session_state.get('additional_request', 'ì¶”ê°€ ìš”ì²­ ì‚¬í•­ ì—†ìŒ')}"
    )

    # ì¹´ë“œ ìƒì„± í˜¸ì¶œ
    if "faiss_path" in st.session_state:
        with st.spinner("ì¹´ë“œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            embeddings_dir = os.path.dirname(st.session_state["faiss_path"])
            card_data = generate_quiz_from_embeddings(
                embeddings_dir,
                st.session_state["additional_request"],
                st.session_state["card_type"],
                st.session_state["question_type"],
            )

        if card_data:
            st.success("ì¹´ë“œ ìƒì„± ì™„ë£Œ!")

            # ì¹´ë“œ ë°ì´í„°ë¥¼ ì„¸ì…˜ì— ì €ì¥
            st.session_state.card_data = card_data
            st.query_params = {"page": "card_display"}  # ì¹´ë“œ í‘œì‹œ í˜ì´ì§€ë¡œ ì´ë™
            st.rerun()
        else:
            st.error("ì¹´ë“œ ìƒì„± ì‹¤íŒ¨!")
    else:
        st.error("FAISS ê²½ë¡œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


# ì¹´ë“œ í‘œì‹œ í˜ì´ì§€ ì¶”ê°€
elif page == "card_display":
    st.title("ì¹´ë“œ ê²°ê³¼")

    card_data = st.session_state.card_data
    card_type = st.session_state.card_type

    if card_data:
        current_card_idx = st.session_state.current_card

        # ì¹´ë“œ ë³´ì—¬ì£¼ê¸° í•¨ìˆ˜ í˜¸ì¶œ
        show_card(card_data, card_type, current_card_idx)

        # HTMLê³¼ CSSë¥¼ ì‚¬ìš©í•´ ë²„íŠ¼ ìŠ¤íƒ€ì¼ ì¶”ê°€
        button_style = """
            <style>
            .stButton button {
                background-color: #4CAF50; /* Green */
                color: white;
                padding: 6px 12px; /* íŒ¨ë”©ì„ ì¤„ì—¬ì„œ ë” ìŠ¬ë¦¼í•˜ê²Œ ë§Œë“¦ */
                border-radius: 5px; /* ë‘¥ê·¼ ëª¨ì„œë¦¬ í¬ê¸°ë¥¼ ì¤„ì„ */
                border: none;
                font-size: 13px; /* í°íŠ¸ í¬ê¸°ë¥¼ ì¤„ì—¬ì„œ ìŠ¬ë¦¼í•˜ê²Œ */
                cursor: pointer;
            }
            .stButton button:hover {
                background-color: #45a049; /* í˜¸ë²„ì‹œ ì•½ê°„ ì–´ë‘ìš´ ìƒ‰ìƒ */
            }
            </style>
        """
        st.markdown(button_style, unsafe_allow_html=True)

        # ë²„íŠ¼ì„ ë‘ ê°œ ë°°ì¹˜ (ìŠ¤íƒ€ì¼ë§ ì ìš©)
        col1, col2, col3 = st.columns([5, 1, 1])  # ì™¼ìª½ì„ ë„“íˆê³  ì˜¤ë¥¸ìª½ì„ ì¢í˜

        with col2:
            if st.button("ì¹´ë“œ ì €ì¥"):
                st.write("ì¹´ë“œ ì €ì¥ë¨")
                save_quiz_to_mongo(card_data, card_type, current_card_idx)

        with col3:
            if st.button("ë‹¤ìŒ ì¹´ë“œ"):
                if card_type == "quiz":
                    max_index = len(card_data["questions"]) - 1
                else:
                    max_index = len(card_data["learning_cards"]) - 1

                if current_card_idx < max_index:
                    st.session_state.current_card += 1
                    st.rerun()  # ë‹¤ìŒ ì¹´ë“œë¡œ ë„˜ì–´ê°
                else:
                    # ë§ˆì§€ë§‰ ì¹´ë“œì´ë©´ ëª¨ë‹¬ ë„ìš°ê¸°
                    quiz_more_prompt()  # ëª¨ë‹¬ í˜¸ì¶œ
    else:
        st.error("ì¹´ë“œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
